{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(cc_pt1)=\n",
    "# Current clamp: Part 1\n",
    "In part 1 of the current clamp section we will cover how to extract data from current clamp acquisitions. We will focus on pulse injections and not cover ramp injections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.layouts import column, gridplot, row\n",
    "from bokeh.models import ColumnDataSource, CustomJS, Slider, Spinner\n",
    "from bokeh.plotting import figure\n",
    "from scipy import optimize, signal, stats\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to load the data. All the data is stored on json files. While this file type is not the most practical for storing electrophysiological data, it is the very convenient since it does not require any third party python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "temp_path = \"https://cdn.jsdelivr.net/gh/LarsHenrikNelson/PatchClampHandbook/data/current_clamp/\"\n",
    "exp_dict = {}\n",
    "for index in range(1, 69):\n",
    "    url = urllib.request.urlopen(temp_path + f\"{index}.json\")\n",
    "    temp = json.load(url)\n",
    "    temp[\"array\"] = np.array(temp[\"array\"])\n",
    "    exp_dict[index] = temp\n",
    "x_array = np.arange(len(exp_dict[1][\"array\"])) / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is look through your data just to see what it looks like. For reference the data in this tutorial is from a layer 5 cell in the ACC of a P16 mouse. \n",
    "- The recorded data is usually in mV, as is the case for this data.\n",
    "- There is a short baseline of about 300 ms before the current injection starts.\n",
    "- There are current injections that make the voltage go negative and ones that the cell goes positive.\n",
    "- There is a point where the positive current injections make the cell spike.\n",
    "- The current injection is finite but also not short enough that only one spike is ever evoked. This is important for calculating the FI curve\n",
    "- There are 4 cycles where the pulse amplitude start at -100 pA and is increased in 25 pA steps until 300 pA is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Initial data\n",
    "source = ColumnDataSource(data={\"x\": np.arange(20000) / 10, \"y\": exp_dict[1][\"array\"]})\n",
    "\n",
    "# Create a plot\n",
    "plot = figure(\n",
    "    x_axis_label=\"Time (ms)\", y_axis_label=\"Voltage (mV)\", width=400, height=300\n",
    ")\n",
    "plot.line(\"x\", \"y\", source=source, line_color=\"black\")\n",
    "spinner = Spinner(title=\"Acquisition\", low=1, high=68, step=1, value=1, width=80)\n",
    "\n",
    "# JavaScript callback to fetch JSON data and update plot\n",
    "callback = CustomJS(\n",
    "    args=dict(source=source, spinner=spinner),\n",
    "    code=\"\"\"\n",
    "    let val = spinner.value\n",
    "    let URL = `https://cdn.jsdelivr.net/gh/LarsHenrikNelson/PatchClampHandbook/data/current_clamp/${val}.json`\n",
    "    fetch(URL)\n",
    "    .then(response => response.json())\n",
    "    .then(data => {\n",
    "        source.data.y = data[\"array\"];\n",
    "        source.change.emit();\n",
    "    })\n",
    "    .catch(error => console.error('Error fetching data:', error));\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "# Add a button to trigger the callback\n",
    "spinner.js_on_change(\"value\", callback)\n",
    "\n",
    "# Layout and show\n",
    "layout = column(spinner, plot)\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will define some important features of the acquisition so that we can reuse the settings throughout the analysis. It is important to note the all the parameters are going to be in samples. The current files were recorded at 10000 Hz so we are multiply the time by 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_start = 0\n",
    "baseline_end = 3000\n",
    "pulse_start = 3000\n",
    "pulse_end = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring delta V and getting the IV curve\n",
    "The first concept we are going to cover is delta V and analyzing the IV (current-voltage curve). Delta V is simply the change in voltage due to the current injection. The IV curve is used to calculate the membrane resistance. Remember that voltage difference = current * resistance ($\\Delta V=IR$). This can be calculated by finding the baseline voltage of the acquisition and subtracting voltage during the pulse. There are some things consider when calculating the voltage during the current injection. There can be changes in voltage due channels that open such as due to HCN channels that cause a sag in the voltage. To get the delta V you can take the mean of just a portion of the current injection. For cells that have a voltage sag, you may actually want to get the mean of the portion around the peak sag. You could also get the delta V by taking the mean after the sag since for cells without $Ih$ currents this will be the steady state of the cell unaffected by capacitance. Other cells show a charging with positive current where the membrane voltage increases linearly over the current injection. I have seen this in dopaminergic cells and MSNs. There are two ways that I would structure the analysis. One is to find the minimum and take the mean of the values around the minimum. The other is to just take the mean over a portion of the current injection. No matter what, you will want to avoid the very beginning of the acquisition since the is membrane is charging due to capacitance. You could also structure your analysis to you use different methods for negative pulses and positive pulses. You could even get $\\Delta V$ by curve fitting and using the amplitude of the fit as $\\Delta V$, however this is risky if your curve does not fit well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "acq = exp_dict[1][\"array\"]\n",
    "x = np.arange(20000) / 10\n",
    "\n",
    "# We define the baseline as the mean of the acquisiton from 0 to 300 ms\n",
    "baseline_v = np.mean(acq[baseline_start:baseline_end])\n",
    "\n",
    "# We define the pulse voltage as the mean of the acquisition for the last 50% of the current injection\n",
    "p50 = ((pulse_end - pulse_start) // 2) + pulse_start\n",
    "injection_v = np.mean(acq[p50:pulse_end])\n",
    "delta_v = injection_v - baseline_v\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.set_xlabel(\"Time (ms)\")\n",
    "_ = ax.set_ylabel(\"Voltage (mV)\")\n",
    "_ = ax.plot(x, acq, color=\"black\", label=\"Acquisition\")\n",
    "_ = ax.plot(\n",
    "    x[baseline_start:baseline_end],\n",
    "    acq[baseline_start:baseline_end],\n",
    "    color=\"#37f2fc\",\n",
    "    label=\"Baseline\",\n",
    ")\n",
    "_ = ax.plot(\n",
    "    np.arange(p50, pulse_end) / 10,\n",
    "    acq[p50:pulse_end],\n",
    "    color=\"#fcba37\",\n",
    "    label=\"Pulse\",\n",
    ")\n",
    "_ = ax.plot(\n",
    "    [p50 / 10, p50 / 10],\n",
    "    [baseline_v, injection_v],\n",
    "    color=\"#fc37fc\",\n",
    "    label=\"Delta V\",\n",
    ")\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will need to measure the delta V for all pulses except those with spikes. The reason that we do not measure the delta V for acquisitions with spikes is that spiking activity is a seperate state compared to non-spiking. So we will simply exclude acquisitions with spikes. We will do this by ignoring acquisitions with voltages greater than -20 mV. We will also need the pulse amplitude of each acquisition which is located in the file.\n",
    "\n",
    "You will notice there is a linear relationship between current and voltage. To get the membrane resistance from these data we just have to run a linear regression between the current and delta V. There are a couple ways that you can run the linear regression. One is you can take all delta Vs, you can take just a subset or you can rectify or take the absolute value of the delta Vs before running the regression. We will do all three since it is easy to do in Python. One really important thing to note is the units of the regressors. current is in pA and delta V is in mV and we need to get to MOhms. To do this we multiply the slope by 1000 to get MOhm. If you run the code below you see that the answers are fairly close. One reason to choose the subset version is that you may change the membrane resistance as the cell gets close to spiking even if it does not spike. However, I have seen all three measures used and many papers never disclose what the current injection range was used for calculating the membrane resistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "p50 = ((pulse_end - pulse_start) // 2) + pulse_start\n",
    "delta_v = []\n",
    "current_amplitude = []\n",
    "for acq_num, acq in exp_dict.items():\n",
    "    voltages = acq[\"array\"]\n",
    "    baseline_v = np.mean(voltages[baseline_start:baseline_end])\n",
    "    acq[\"baseline_v\"] = baseline_v\n",
    "    if np.max(voltages) < -20:\n",
    "        current_amplitude.append(acq[\"pulse_amp\"])\n",
    "        injection_v = np.mean(voltages[p50:pulse_end])\n",
    "        delta_v.append(injection_v - baseline_v)\n",
    "        acq[\"delta_v\"] = injection_v - baseline_v\n",
    "    else:\n",
    "        acq[\"delta_v\"] = np.nan\n",
    "\n",
    "mem_res_all = stats.linregress(current_amplitude, delta_v)\n",
    "subset = np.where(np.array(current_amplitude) <= 50)[0]\n",
    "mem_res_subset = stats.linregress(\n",
    "    np.array(current_amplitude)[subset], np.array(delta_v)[subset]\n",
    ")\n",
    "mem_res_rectified = stats.linregress(np.abs(current_amplitude), np.abs(delta_v))\n",
    "\n",
    "# \\n is just added to print on separate lines\n",
    "print(\n",
    "    f\"All values: {mem_res_all.slope * 1000}\",\n",
    "    f\"Subset: {mem_res_subset.slope * 1000}\",\n",
    "    f\"Rectified: {mem_res_rectified.slope * 1000}\",\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "x_fit = np.linspace(min(current_amplitude), max(current_amplitude), num=50)\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.grid(which=\"both\", color=\"0.95\")\n",
    "ax.set_axisbelow(True)\n",
    "_ = ax.set_xlabel(\"Current (pA)\")\n",
    "_ = ax.set_ylabel(\"Delta V (mV)\")\n",
    "_ = ax.scatter(\n",
    "    current_amplitude, delta_v, facecolor=\"grey\", edgecolor=\"grey\", s=60, alpha=0.6\n",
    ")\n",
    "_ = ax.plot(\n",
    "    x_fit,\n",
    "    mem_res_all.intercept + x_fit * mem_res_all.slope,\n",
    "    label=\"Fit all\",\n",
    "    color=\"#fcba37\",\n",
    "    linewidth=2,\n",
    ")\n",
    "_ = ax.plot(\n",
    "    x_fit,\n",
    "    mem_res_subset.intercept + x_fit * mem_res_subset.slope,\n",
    "    label=\"Fit subset\",\n",
    "    color=\"#fc37fc\",\n",
    "    linewidth=2,\n",
    ")\n",
    "_ = ax.plot(\n",
    "    x_fit,\n",
    "    mem_res_rectified.intercept + x_fit * mem_res_rectified.slope,\n",
    "    label=\"Fit rectified\",\n",
    "    color=\"#37f2fc\",\n",
    "    linewidth=2,\n",
    ")\n",
    "_ = ax.legend()\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"top\"].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ih voltage sag\n",
    "Hyperpolarization-activated cyclic nucleotideâ€“gated (HCN) channels are typically responsible for the voltage sag in a current clamp acquisitions. Voltage sag is when the voltage drop is initially larger at the beginning of the current injection than at the end. Many cell types have Ih voltage sag such as dopaminergic cells and layer 5 pyramidal neurons. Measuring voltage sag is fairly straightforward. You just measure the voltage difference between the peak sag and and the voltage in the second half of the current injection similar to measuring delta V. The main way I have seen voltage sag reported is by measuring the sag on the most negative current injection. You could also technically run an IV curve for the voltage sag. To truly determine whether the voltage sag is due to HCN channels you would need to do a flow-in experiment with the drug ZD7288. If you want to run the IV curve I challenge you to modify the IV code above to get the resistance of the channels contributing to the voltage sag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p50 = ((pulse_end - pulse_start) // 2) + pulse_start\n",
    "delta_v = []\n",
    "current_amplitude = []\n",
    "sag_loc = []\n",
    "acqs = []\n",
    "for acq_num, acq in exp_dict.items():\n",
    "    voltages = acq[\"array\"]\n",
    "    if acq[\"pulse_amp\"] == -100:\n",
    "        acqs.append(voltages)\n",
    "        current_amplitude.append(acq[\"pulse_amp\"])\n",
    "        sag_v = np.min(voltages[pulse_start:p50])\n",
    "        sag_loc.append(np.argmin(voltages[pulse_start:p50]) + pulse_start)\n",
    "        injection_v = np.mean(voltages[p50:pulse_end])\n",
    "        delta_v.append(sag_v - injection_v)\n",
    "        acq[\"Sag (mV)\"] = sag_v\n",
    "        acq[\"Sag (ms)\"] = np.argmin(voltages[pulse_start:p50]) + pulse_start\n",
    "    else:\n",
    "        acq[\"Sag (mV)\"] = np.nan\n",
    "        acq[\"Sag (ms)\"] = np.nan\n",
    "print(f\"Voltage sag: {np.mean(delta_v):.3f} mV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm that the voltage sag was correctly measured. Note that when we collected the sag location above we collected the sample number so that needs to be converted to time in ms by dividing by 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "for sloc, dv, vs, a in zip(sag_loc, delta_v, acqs, ax.flat):\n",
    "    a.plot(x_array, vs, color=\"black\")\n",
    "    a.plot(\n",
    "        [sloc / 10, sloc / 10],\n",
    "        [vs[sloc], vs[sloc] - dv],\n",
    "        color=\"#fc37fc\",\n",
    "        linewidth=3,\n",
    "    )\n",
    "    a.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rheobase\n",
    "Rheobase is the minimum current required to get a cell to spike. This measure is directly related to membrane resistance through the equation: V=IR. When resistence increases, the current need to achieve the same delta V decreases. This means that a cell will higher membrane resistance will likely need less synaptic to be able to spike. There are a couple ways you can find rheobase. Find the minimum current needed to get the cell to spike out of all 4 cycles. I do not recommend this since there is variability between cycles and the variability could be affected by a treatment or other factors. Find the minimum current needed to get the cell to spike for each cycle and average the result. This is the method I recommend. The way I find rheobase below depends on the acquisitions being assigned to a cycle (1 to inf) which ClampSuite automatically. This may not be the case for your data. There are other ways to find rheobase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rheobase = []\n",
    "rheobase_acq = []\n",
    "exp_dict[1][\"rheobase\"] = False\n",
    "for index in range(2, len(exp_dict) + 1):\n",
    "    exp_dict[index][\"rheobase\"] = False\n",
    "    if (np.max(exp_dict[index][\"array\"]) > 30) & (\n",
    "        np.max(exp_dict[index - 1][\"array\"]) < 30\n",
    "    ):\n",
    "        rheobase.append(exp_dict[index][\"pulse_amp\"])\n",
    "        rheobase_acq.append(index)\n",
    "        exp_dict[index][\"rheobase\"] = True\n",
    "print(f\"Rheobase: {np.mean(rheobase)} pA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm that we have the right rheobase values by plotting the rheobase acquistion in red and the previous acquisition in black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plots = []\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "for acq, ax in zip(rheobase_acq, axes.flat):\n",
    "    ax.plot(x_array, exp_dict[acq - 1][\"array\"], color=\"black\", linewidth=1)\n",
    "    ax.plot(x_array, exp_dict[acq][\"array\"], color=\"red\", linewidth=1)\n",
    "    ax.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike frequency measures\n",
    "There are two important measures that we can get from the spike frequency of a cell. We can get the [FI curve](current_clamp) that can be used to determine the changes in gain of a cell. We can also get the spike frequency adaptation; how consistently the cell spikes or whether the spikes are speeding up or slowing down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid fit the FI curve to get the gain and max firing rate\n",
    "Many papers will just analyze their FI data using a repeated measures ANOVA. However, this method only tells whether or not the FI curves are different and where they are different. To get a better idea of why the curves are different you really need to fit a sigmoid function data for each cell. This will get you the gain of a cell or the slope of the FI curve as well as the estimated maximum firing rate and the current offset. This is a simple example of how to do this in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def sigmoid(x, max_value, midpoint, slope, offset):\n",
    "    return 1 / (1 + np.exp((x - midpoint) / slope)) * max_value + offset\n",
    "\n",
    "\n",
    "x = np.linspace(0, 400)\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(10,4))\n",
    "ax[0].set_title(\"Input gain difference\")\n",
    "ax[0].plot(x, sigmoid(x, 17, 200, -40, 0))\n",
    "ax[0].plot(x, sigmoid(x, 17, 170, -30, 0), color=\"orange\")\n",
    "ax[1].set_title(\"Response gain difference\")\n",
    "ax[1].plot(x, sigmoid(x, 20, 200, -40, 0))\n",
    "ax[1].plot(x, sigmoid(x, 17, 200, -40, 0), color=\"orange\")\n",
    "ax[2].set_title(\"Rheobase difference\")\n",
    "ax[2].plot(x, sigmoid(x, 17, 200, -40, 0))\n",
    "ax[2].plot(x, sigmoid(x, 17, 150, -40, 0), color=\"orange\")\n",
    "for i in ax:\n",
    "    i.spines[\"right\"].set_visible(False)\n",
    "    i.spines[\"top\"].set_visible(False)\n",
    "    i.grid(axis='both', color='0.95')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a simple interactive plot where you can play arount with the slope, max value and the midpoint of two sigmoid curves to get an idea of how each of the factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def sigmoid(x, max_value, midpoint, slope, offset):\n",
    "    return 1 / (1 + np.exp((x - midpoint) / slope)) * max_value + offset\n",
    "\n",
    "\n",
    "x = np.linspace(0, 400)\n",
    "y1 = sigmoid(x, 16.0, 200.0, -40.0, 0)\n",
    "y2 = sigmoid(x, 16.0, 200.0, -40.0, 0)\n",
    "\n",
    "source1 = ColumnDataSource({\"x\": np.linspace(0, 400), \"y1\": y1, \"y2\": y2})\n",
    "source2 = ColumnDataSource(\n",
    "    {\"x\": np.linspace(0, 400, num=49), \"y1\": np.diff(y1), \"y2\": np.diff(y2)}\n",
    ")\n",
    "\n",
    "plot1 = figure(width=300, height=300)\n",
    "plot1.line(\"x\", \"y1\", source=source1, line_width=3, line_alpha=0.6)\n",
    "plot1.line(\"x\", \"y2\", source=source1, line_width=3, line_alpha=0.6, line_color=\"orange\")\n",
    "plot2 = figure(width=300, height=300)\n",
    "plot2.line(\"x\", \"y1\", source=source2, line_width=3, line_alpha=0.6)\n",
    "plot2.line(\"x\", \"y2\", source=source2, line_width=3, line_alpha=0.6, line_color=\"orange\")\n",
    "\n",
    "max_val_1 = Slider(value=16.0, start=10.0, end=30.0, step=1.0, title=\"Response gain 1\")\n",
    "slope_1 = Slider(value=-40, end=-5.0, start=-60.0, step=1.0, title=\"Input gain 1\")\n",
    "midpoint_1 = Slider(\n",
    "    value=200.0, start=25.0, end=400.0, step=1.0, title=\"Current offset 1\"\n",
    ")\n",
    "\n",
    "callback = CustomJS(\n",
    "    args=dict(\n",
    "        source1=source1,\n",
    "        source2=source2,\n",
    "        max_val_1=max_val_1,\n",
    "        slope_1=slope_1,\n",
    "        midpoint_1=midpoint_1,\n",
    "    ),\n",
    "    code=\"\"\"\n",
    "    const data = source1.data;\n",
    "    const x_array = data['x'];\n",
    "    const y1 = x_array.map((x) => {\n",
    "        return 1 / (1 + Math.exp((x - midpoint_1.value) / slope_1.value)) * max_val_1.value\n",
    "    })\n",
    "    source1.data['y1'] = y1\n",
    "    const y1_diff = y1.slice(1).map((value, index) => value - y1[index])\n",
    "    source2.data['y1'] = y1_diff\n",
    "    source1.change.emit();\n",
    "    source2.change.emit();\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "max_val_1.js_on_change(\"value\", callback)\n",
    "slope_1.js_on_change(\"value\", callback)\n",
    "midpoint_1.js_on_change(\"value\", callback)\n",
    "\n",
    "show(\n",
    "    column(\n",
    "        column(max_val_1, slope_1, midpoint_1),\n",
    "        gridplot([[plot1, plot2]]),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the data to a sigmoid curve\n",
    "First let's look at the FI data that we extracted from the acquisitions. We are going to curve fit the FI curve. We will use Scipy's [curve_fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html). This function needs a function passed to it, in this case it is the sigmoid function as well as an array for the x values and y values. There are many other factors that you could pass, such as bounding factors but are not needed in this case. Lastly you can fit the entire array of current values, however neurons will only spike when there is a net positive current injection. We can truncate our arrays of current and hertz so that only the pairs that have a current >= 0 are kept. You can fit the sigmoid curve to whole set of data and it will likely fit well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_analysis = {\"acqs\": [], \"hertz\": [], \"current\": [], \"peaks\": [], \"voltages\": []}\n",
    "time = (pulse_end - pulse_start) / 10000\n",
    "\n",
    "for acq_num, acq in exp_dict.items():\n",
    "    voltages = np.array(acq[\"array\"])\n",
    "    peaks, _ = signal.find_peaks(\n",
    "        voltages[pulse_start:pulse_end],\n",
    "        height=10,\n",
    "        prominence=10,\n",
    "    )\n",
    "    peaks += pulse_start\n",
    "    spike_analysis = {}\n",
    "    spike_analysis[\"hertz\"] = len(peaks) / time\n",
    "    spike_analysis[\"current\"] = acq[\"pulse_amp\"]\n",
    "    spike_analysis[\"peaks\"] = peaks\n",
    "    spike_analysis[\"voltages\"] = voltages[peaks]\n",
    "    acq.update(spike_analysis)\n",
    "\n",
    "current = np.array([i[\"current\"] for i in exp_dict.values()])\n",
    "hertz = np.array([i[\"hertz\"] for i in exp_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "indexes = np.where(current >= 0)[0]\n",
    "lb = [-np.inf, -np.inf, 1e-6, 0]\n",
    "ub = [np.inf, np.inf, np.inf, np.inf]\n",
    "p0 = [np.max(hertz[indexes]), np.mean(current[indexes]), 30, 0]\n",
    "p, _ = optimize.curve_fit(sigmoid, current[indexes], hertz[indexes])\n",
    "fit_x = np.linspace(0, max(current), 1000)\n",
    "fit_y = sigmoid(fit_x, p[0], p[1], p[2], p[3])\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(10,3.5))\n",
    "ax[0].set_xlabel(\"Current (pA)\")\n",
    "ax[0].set_ylabel(\"Firing rate (Hertz)\")\n",
    "ax[0].scatter(\n",
    "    current,\n",
    "    hertz,\n",
    "    color=\"black\",\n",
    "    edgecolor=\"grey\",\n",
    "    s=60,\n",
    "    alpha=0.6,\n",
    ")\n",
    "ax[0].plot(fit_x, fit_y, linewidth=2)\n",
    "\n",
    "diff = np.diff(fit_y)\n",
    "max_gain_index = diff.argmax()\n",
    "max_gain = diff[max_gain_index]\n",
    "max_current = fit_x[max_gain_index]\n",
    "\n",
    "ax[1].set_xlabel(\"Current (pA)\")\n",
    "ax[1].set_ylabel(\"Gain (slope)\")\n",
    "\n",
    "ax[1].plot(fit_x[1:], diff, linewidth=2)\n",
    "ax[1].axvline(\n",
    "    x=max_current, color=\"orange\", linewidth=2\n",
    ")\n",
    "for i in ax:\n",
    "    i.spines[\"right\"].set_visible(False)\n",
    "    i.spines[\"top\"].set_visible(False)\n",
    "    i.grid(which=\"both\")\n",
    "    i.set_axisbelow(True)\n",
    "\n",
    "print(\n",
    "    f\"Slope (gain): {p[2]}\",\n",
    "    f\"Max value: {p[0]}\",\n",
    "    f\"Midpoint: {p[1]}\",\n",
    "    f\"Max gain: {max_gain}\",\n",
    "    sep=\"\\n\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spike adaptation index\n",
    "Spike adaptation is a way to quantify whether IEI is stable or not. Some cells such as fast spiking interneurons have an extremely stable IEI that changes very little as spike frequency increases. Other cells types such as layer 5 pyramidal cells have an IEI that increase as spike frequency increases. There are many ways to calculate the spike adaptation and we will cover a few of them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Allen institute method\n",
    "This method is ideal if you want to know if your IEIs are increasing or decreasing since the values will be bound as -1 and 1. A negative value means the spikes are slowing down and positive value means the spikes are speeding up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = []\n",
    "npeaks = []\n",
    "for acq in exp_dict.values():\n",
    "    acq[\"ai_sfa\"] = np.nan\n",
    "    p = acq[\"peaks\"]\n",
    "    if len(p) > 2:\n",
    "        iei = np.diff(p)\n",
    "        if np.allclose((iei[1:] + iei[:-1]), 0.0):\n",
    "            spike_adapt = np.nan\n",
    "        norm_diffs = (iei[1:] - iei[:-1]) / (iei[1:] + iei[:-1])\n",
    "        norm_diffs[(iei[1:] == 0) & (iei[:-1] == 0)] = 0.0\n",
    "        spike_adapt = np.nanmean(norm_diffs)\n",
    "        sa.append(spike_adapt)\n",
    "        acq[\"ai_sfa\"] = spike_adapt\n",
    "        npeaks.append(len(p))\n",
    "fig, ax = plt.subplots()\n",
    "print(np.mean(sa))\n",
    "ax.set_xlabel(\"Number of Spikes\")\n",
    "ax.set_ylabel(\"Spike adaptation\")\n",
    "ax.grid(which=\"both\")\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "_ = ax.plot(npeaks, sa, \"o\", markersize=10, markerfacecolor=\"grey\", markeredgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficient of variation (CV)\n",
    "This is the simplest method. The coefficient of variation (CV) is the standard deviation of IEIs divided by the mean IEI. The CV measures the dispersion of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = []\n",
    "npeaks = []\n",
    "for acq in exp_dict.values():\n",
    "    p = acq[\"peaks\"]\n",
    "    acq[\"cv\"] = np.nan\n",
    "    if len(p) > 1:\n",
    "        iei = np.diff(p)\n",
    "        spike_adapt = np.std(iei) / np.mean(iei)\n",
    "        sa.append(spike_adapt)\n",
    "        npeaks.append(len(p))\n",
    "        acq[\"cv\"] = spike_adapt\n",
    "fig, ax = plt.subplots()\n",
    "print(np.mean(sa))\n",
    "ax.set_xlabel(\"Number of Spikes\")\n",
    "ax.set_ylabel(\"Spike adaptation\")\n",
    "ax.grid(which=\"both\")\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "_ = ax.plot(npeaks, sa, \"o\", markersize=10, markerfacecolor=\"grey\", markeredgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local variation\n",
    "Local variation is from Shinomoto et al., 2009 [@shinomoto_relating_2009]. One problem with the CV is that vastly different spike patterns can result in the same CV. Shinomoto developed an equation that get around that issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = []\n",
    "npeaks = []\n",
    "for acq in exp_dict.values():\n",
    "    p = acq[\"peaks\"]\n",
    "    acq[\"local_sfa\"] = np.nan\n",
    "    if len(p) > 2:\n",
    "        iei = np.diff(p)\n",
    "        isi_shift = iei[1:]\n",
    "        isi_cut = iei[:-1]\n",
    "        n_minus_1 = len(isi_cut)\n",
    "        local_var = (\n",
    "            np.sum((3 * (isi_cut - isi_shift) ** 2) / (isi_cut + isi_shift) ** 2)\n",
    "            / n_minus_1\n",
    "        )\n",
    "        sa.append(local_var)\n",
    "        acq[\"loca_sfa\"] = local_var\n",
    "        npeaks.append(len(p))\n",
    "fig, ax = plt.subplots()\n",
    "print(np.mean(sa))\n",
    "ax.set_xlabel(\"Number of Spikes\")\n",
    "ax.set_ylabel(\"Spike adaptation\")\n",
    "ax.grid(which=\"both\")\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "_ = ax.plot(npeaks, sa, \"o\", markersize=10, markerfacecolor=\"grey\", markeredgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Revised local variation\n",
    "Revised local variation is from Shinomoto et al., 2009 [@shinomoto_relating_2009]. One problem with the CV is that vastly different spike patterns can result in the same CV. Shinomoto originally developed the local variation equation to fix this issue, however they later adjusted the equation to account for the refactory period of the neuron in being analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = []\n",
    "npeaks = []\n",
    "\n",
    "# Generic refactory periond of 2 ms will work.\n",
    "R = 2\n",
    "for acq in exp_dict.values():\n",
    "    p = acq[\"peaks\"]\n",
    "    acq[\"rlocal_sfa\"] = np.nan\n",
    "    if len(p) > 2:\n",
    "        iei = np.diff(p / 10)\n",
    "        isi_shift = iei[1:]\n",
    "        isi_cut = iei[:-1]\n",
    "        isi_add = isi_cut + isi_shift\n",
    "        left = 1 - ((4 * isi_cut * isi_shift) / isi_add**2)\n",
    "        right = 1 + ((4 * R) / isi_add)\n",
    "        var = 3 * np.sum(left * right) * len(isi_shift)\n",
    "        sa.append(var)\n",
    "        acq[\"rlocal_sfa\"] = var\n",
    "        npeaks.append(len(p))\n",
    "fig, ax = plt.subplots()\n",
    "print(np.mean(sa))\n",
    "ax.set_xlabel(\"Number of Spikes\")\n",
    "ax.set_ylabel(\"Spike adaptation\")\n",
    "ax.grid(which=\"both\")\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "_ = ax.plot(npeaks, sa, \"o\", markersize=10, markerfacecolor=\"grey\", markeredgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike threshold\n",
    "Spike threshold is tells you at what voltage a cells spike is elicited. This different from rheobase. Spike threhold is primarly set by the number of sodium channels on the axon hillock. The spike threshold is important because it is a bifurcation point in the function of a neuron. If you want to read more about this I suggest reading \"Dynamical systems in neuroscience: the geometry of excitability and bursting\" [@izhikevich_dynamical_2007]. A lower spike threshold can show up as a lower rheobase in neurons whose voltage continues to rise during the current injection before a spike occurs. I have seen this occur in cortical pyramidal neurons and spiny projection neurons but not parvalbumin inhibitory neurons.\n",
    "\n",
    "You can measure spike threshold on any acquisition that has a spike, however usually just the spikes from the rheobase acquisitions are used to calculate the spike threshold. There are several ways to calculate the spike threshold such a the first derivative, second derivative, third derivative, and a max curvature [@sekerli_estimating_2004]. I find the third derivative and method VII to be the most consistent. We will use the third derivative method in this tutorial. The way I typically differentiate signals is by using Numpy's [gradient](https://numpy.org/doc/stable/reference/generated/numpy.gradient.html). Unlike [diff](https://numpy.org/doc/stable/reference/generated/numpy.diff.html), [gradient](https://numpy.org/doc/stable/reference/generated/numpy.gradient.html) returns an array of the same length as the input signal which makes downstream analysis easier. It has the downside in that if you have small peaks you will get some artifacts in the signal which upsampling can counteract. One problem I found with the third derivative is that the peaks found a usually to late by 1 sample at 10000 Hz so I adjust the spike threshold backwards by 1 sample. I also z-score the derivative since this keeps the peak finding threshold consistent between acquisitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets look a single acquisition and see how the different derivatives look. One thing we are going to do just for visualization purposes is limit the extent of the x-axis so that we are just looking at the first spike and for a point of reference we are going to use the spike peak. If you look at the third derivative we want to extract the first positive peak. There are some additions that I have found are helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "voltages = np.array(exp_dict[rheobase_acq[0]][\"array\"])\n",
    "peak = exp_dict[rheobase_acq[0]][\"peaks\"][0] - pulse_start\n",
    "\n",
    "# grab the voltages just inside the current pulse\n",
    "voltages = voltages[pulse_start:pulse_end]\n",
    "x = np.arange(voltages.size)\n",
    "\n",
    "# First derivative\n",
    "dv = np.gradient(voltages)\n",
    "# Second derivative\n",
    "ddv = np.gradient(dv)\n",
    "# Third derivateive\n",
    "dddv = np.gradient(ddv)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, constrained_layout=True)\n",
    "ax = ax.flat\n",
    "for index, j in enumerate([(\"Voltage (mV)\", voltages), (\"dV\",dv), (\"ddV\", ddv), (\"dddV\",dddv)]):\n",
    "    ax[index].set_title(j[0])\n",
    "    ax[index].plot(x[1120:1220], j[1][1120:1220])\n",
    "    ax[index].axvline(peak, color=\"orange\", linewidth=2)\n",
    "    ax[index].grid(which='both')\n",
    "    ax[index].spines[\"top\"].set_visible(False)\n",
    "    ax[index].spines[\"right\"].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to calculate the spike threshold for every spike in an acquisition that contains spikes. We will use the third derivative method. To do this we will create two functions. One to find a spike threshold for a single spike in a window. The second function will loop through all of the spikes to find the spike threshold using a different start and stop values for each spike. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_spk_threshold(voltages: np.array, start: int, end: int):\n",
    "    dv = np.gradient(voltages)\n",
    "    ddv = np.gradient(dv)\n",
    "    dddv = np.gradient(ddv)\n",
    "\n",
    "    temp = dddv[start:end]\n",
    "    base = temp.argmin()\n",
    "    index = base - 1\n",
    "    val = temp[base] - temp[index]\n",
    "    while val < 0:\n",
    "        index -= 1\n",
    "        base -= 1\n",
    "        val = temp[base] - temp[index]\n",
    "    thresh_peak = start + index\n",
    "    return thresh_peak\n",
    "\n",
    "\n",
    "def find_all_spk_thresholds(voltages, peaks, pulse_start, pulse_end):\n",
    "    output = np.zeros(len(peaks), dtype=int)\n",
    "    start_index = pulse_start\n",
    "    for index in range(len(peaks)):\n",
    "        if index < (len(peaks) - 1):\n",
    "            end_index = peaks[index]\n",
    "        else:\n",
    "            end_index = pulse_end\n",
    "        output[index] = find_spk_threshold(voltages, start_index, end_index)\n",
    "        start_index = peaks[index]\n",
    "    return output\n",
    "\n",
    "\n",
    "for acq in exp_dict.values():\n",
    "    voltages = np.array(acq[\"array\"])\n",
    "    peaks = acq[\"peaks\"]\n",
    "    if len(peaks) > 0:\n",
    "        output = find_all_spk_thresholds(voltages, peaks, pulse_start, pulse_end)\n",
    "        acq[\"threshold_index\"] = output\n",
    "    else:\n",
    "        acq[\"threshold_index\"] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the spike threshold we are only going to get the spike threshold for the first spike of each rheobase acquisition. This is pretty common practice. Let's inspect the output. While it may look like the spike threshold is climbing up the spike a little bit, it is important to remember what a failed spike looks like. There is often a hump suggesting there is a small and rapid climb in voltage before a spike can occur even if the spike does not occur. We are trying to find that bifurcation point. Unfortunately, I did not include an acquisition with a failed spike to show the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "figures = []\n",
    "\n",
    "spike_threshold_x = []\n",
    "spike_threshold_y = []\n",
    "for i in rheobase_acq:\n",
    "    index = exp_dict[i][\"threshold_index\"][0]\n",
    "    spike_threshold_y.append(exp_dict[i][\"array\"][index])\n",
    "    spike_threshold_x.append(index)\n",
    "\n",
    "temp = {str(i): exp_dict[i][\"array\"] for i in rheobase_acq}\n",
    "x = np.arange(len(temp[str(rheobase_acq[0])])) / 10\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, constrained_layout=True)\n",
    "ax = ax.flat\n",
    "for sx, sy, acq_num, a in zip(spike_threshold_x, spike_threshold_y, rheobase_acq, ax):\n",
    "    a.set_xlabel(\"Time (ms)\")\n",
    "    a.set_ylabel(\"Voltage (mV)\")\n",
    "    a.plot(x[sx-50:sx+100], exp_dict[acq_num][\"array\"][sx-50:sx+100])\n",
    "    a.plot(sx/10, sy, \"o\")\n",
    "    a.grid(which=\"both\")\n",
    "    a.spines[\"top\"].set_visible(False)\n",
    "    a.spines[\"right\"].set_visible(False)\n",
    "\n",
    "print(f\"Spike threshold: {np.mean(spike_threshold_y):.3f} mV\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike half-width and width\n",
    "The next waveform feature that we can measure is the spike (half) width. Half width is important because it can help you determine if there is broadening or shortening of the waveform. Broadening of the waveform can be due to inactivation of the voltage-gated potassium channels, slower-inactivating sodium channels or even decreased activation of voltage-gated calcium channels. Wavefrom broadening increases synaptic output by increasing release probability by increasing the time calcium is in the presynapse [@zbili_past_2019]. This is where the voltage crosses half way between the spike threshold and peak. One important caveat of measuring spike width as the half-way point is that if your spike threshold or peak is changed then your half-width will likely be different.\n",
    "\n",
    "We will also measure the full spike width defined as the length of time it takes to go from spike threshold to spike threshold for a single spike. From this we can pull the depolarization time and repolarization time. It is easier to see that the spike is asymmetric with the depolarization being faster than the repolarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_spk_width(voltages: np.array, start: int, end: int):\n",
    "    start = int(start)\n",
    "    end = int(end)\n",
    "    volts = np.asarray(voltages[start:end])\n",
    "    xvals = np.linspace(start, end, num=int((end - start) * 10))\n",
    "    x = np.linspace(start, end, num=int(end - start))\n",
    "    volts = np.interp(xvals, x, volts)\n",
    "    spike_threshold = voltages[start]\n",
    "    masked_array = volts.copy()\n",
    "    mask = np.array(volts > spike_threshold)\n",
    "    peak_x = np.argmax(volts)\n",
    "    masked_array[~mask] = spike_threshold\n",
    "    hw = signal.peak_widths(masked_array, [peak_x], rel_height=0.5)\n",
    "    fw = signal.peak_widths(masked_array, [peak_x], rel_height=1)\n",
    "    return (\n",
    "        hw[2][0] / 10 + start,\n",
    "        hw[3][0] / 10 + start,\n",
    "        hw[1][0],\n",
    "        fw[2][0] / 10 + start,\n",
    "        fw[3][0] / 10 + start,\n",
    "        fw[1][0],\n",
    "    )\n",
    "\n",
    "\n",
    "def find_all_spk_widths(voltages, spike_thresholds, pulse_end):\n",
    "    width_keys = [\"hw_left\", \"hw_right\", \"hw_y\", \"fw_left\", \"fw_right\", \"fw_y\"]\n",
    "    width = {key: np.zeros(len(peaks)) for key in width_keys}\n",
    "    for index in range(len(peaks)):\n",
    "        if index < (len(peaks) - 1):\n",
    "            end = spike_thresholds[index + 1]\n",
    "        else:\n",
    "            # Adding 2000 samples (or 2 ms) to the end helps with spikes that occur just before the end of the acquisition\n",
    "            if (pulse_end - spike_thresholds[index]) < 2000:\n",
    "                end = spike_thresholds[index] + 2000\n",
    "            else:\n",
    "                end = pulse_end\n",
    "        output = find_spk_width(\n",
    "            voltages,\n",
    "            spike_thresholds[index],\n",
    "            end,\n",
    "        )\n",
    "        for key, value in zip(width_keys, output):\n",
    "            width[key][index] = value\n",
    "    return width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_width_x = []\n",
    "spike_width_y = []\n",
    "for acq in exp_dict.values():\n",
    "    voltages = acq[\"array\"]\n",
    "    spk_thresholds = acq[\"threshold_index\"]\n",
    "    peaks = acq[\"peaks\"]\n",
    "    if len(peaks) > 0:\n",
    "        hws = find_all_spk_widths(voltages, spk_thresholds, pulse_end)\n",
    "        acq.update(hws)\n",
    "    else:\n",
    "        width_keys = [\"hw_left\", \"hw_right\", \"hw_y\", \"fw_left\", \"fw_right\", \"fw_y\"]\n",
    "        width = {key: None for key in width_keys}\n",
    "        acq.update(width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the spike width we are only going to get the spike width for the first spike of each rheobase acquisition. This is pretty common practice. We can also inspect the spike width measurements to make sure they are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "figures = []\n",
    "hw = []\n",
    "fw = []\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, constrained_layout=True)\n",
    "ax = ax.flat\n",
    "for acq_num, a in zip(rheobase_acq, ax):\n",
    "    acq = exp_dict[acq_num]\n",
    "    sx = [acq[\"hw_left\"][0], acq[\"hw_right\"][0]]\n",
    "    sy = acq[\"hw_y\"][0]\n",
    "    sy = [sy, sy]\n",
    "    hw.append((sx[1] - sx[0]) / 10)\n",
    "    array = exp_dict[acq_num][\"array\"]\n",
    "\n",
    "    a.set_xlabel(\"Time (ms)\")\n",
    "    a.set_ylabel(\"Voltage (mV)\")\n",
    "    a.grid(which=\"both\")\n",
    "    a.spines[\"top\"].set_visible(False)\n",
    "    a.spines[\"right\"].set_visible(False)\n",
    "    a.plot(x, array, color=\"black\")\n",
    "    a.set_xlim(sx[0]/10-5, sx[0]/10+10)\n",
    "    a.set_ylim(-50,45)\n",
    "    a.plot(np.array(sx)/10, sy, color=\"orange\")\n",
    "\n",
    "    sx = [acq[\"fw_left\"][0], acq[\"fw_right\"][0]]\n",
    "    sy = acq[\"fw_y\"][0]\n",
    "    sy = [sy, sy]\n",
    "    fw.append((sx[1] - sx[0]) / 10)\n",
    "    a.plot(np.array(sx)/10, sy, color=\"magenta\")\n",
    "\n",
    "print(f\"Spike half-width: {np.mean(hw):.3f} ms\")\n",
    "print(f\"Spike width: {np.mean(fw):.3f} ms\")\n",
    "# show(gridplot([figures[:2], figures[2:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike Area Under the Curve (AUC)\n",
    "Spike AUC is similar to spike width except that it is the sum of the interaction between spike threshold, peak spike voltage and the spike width. The AUC can be calculated by integrating the spike from the spike threshold to spike threshold. Since we have evenly spaced samples we can use a simple integrating function Numpy's [trapezoid](https://numpy.org/stable/reference/generated/numpy.trapezoid.html). To improve the quality of the AUC measure we will upsample by 10x. This is probably not need but it is fast and adds very little code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_spk_auc(voltages: np.array, start: int, end: int):\n",
    "    volts = np.asarray(voltages[int(start) : int(end)])\n",
    "    spike_threshold = voltages[start]\n",
    "    x = np.arange(len(volts))\n",
    "    xvals = np.linspace(x[0], x[-1], num=x.size * 10)\n",
    "    yinterp = np.interp(xvals, x, volts)\n",
    "    peak = np.argmax(yinterp)\n",
    "    indices = np.where(yinterp > spike_threshold)[0]\n",
    "    splits = np.where(np.diff(indices) > 1)[0]\n",
    "    if len(splits) > 0:\n",
    "        indices = indices[: splits[0]]\n",
    "    yinterp = yinterp - yinterp[indices[0]]\n",
    "    auc = (\n",
    "        np.trapezoid(yinterp[indices[:-1]], dx=x[1] / 10 - x[0] / 10),\n",
    "        np.trapezoid(yinterp[indices[0] : peak + 1], dx=x[1] / 10 - x[0] / 10),\n",
    "        np.trapezoid(yinterp[peak : indices[-1] + 1], dx=x[1] / 10 - x[0] / 10),\n",
    "    )\n",
    "    return auc\n",
    "\n",
    "\n",
    "def find_all_spk_auc(voltages, spike_thresholds, pulse_end):\n",
    "    auc_keys = [\"auc\", \"auc_left\", \"auc_right\"]\n",
    "    auc = {key: np.zeros(len(spike_thresholds)) for key in auc_keys}\n",
    "    for index in range(len(spike_thresholds)):\n",
    "        if index < (len(spike_thresholds) - 1):\n",
    "            end = spike_thresholds[index + 1]\n",
    "        else:\n",
    "            # Adding 2000 samples (or 2 ms) to the end helps with spikes that occur just before the end of the acquisition\n",
    "            if (pulse_end - spike_thresholds[index]) < 2000:\n",
    "                end = spike_thresholds[index] + 2000\n",
    "            else:\n",
    "                end = pulse_end\n",
    "        output = find_spk_auc(\n",
    "            voltages,\n",
    "            spike_thresholds[index],\n",
    "            end,\n",
    "        )\n",
    "        for key, value in zip(auc_keys, output):\n",
    "            auc[key][index] = value\n",
    "    return auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "spike_width_x = []\n",
    "spike_width_y = []\n",
    "for acq in exp_dict.values():\n",
    "    voltages = acq[\"array\"]\n",
    "    spk_thresholds = acq[\"threshold_index\"]\n",
    "    peaks = acq[\"peaks\"]\n",
    "    if len(peaks) > 0:\n",
    "        auc = find_all_spk_auc(voltages, spk_thresholds, pulse_end)\n",
    "        acq.update(auc)\n",
    "    else:\n",
    "        auc_keys = [\"auc\", \"auc_left\", \"auc_right\"]\n",
    "        auc = {key: None for key in auc_keys}\n",
    "        acq.update(auc)\n",
    "\n",
    "auc = []\n",
    "auc_left = []\n",
    "auc_right = []\n",
    "for i in rheobase_acq:\n",
    "    auc.append(exp_dict[i][\"auc\"][0])\n",
    "    auc_left.append(exp_dict[i][\"auc_left\"][0])\n",
    "    auc_right.append(exp_dict[i][\"auc_right\"][0])\n",
    "print(f\"AUC: {np.mean(auc):.3f}\")\n",
    "print(f\"Left AUC: {np.mean(auc_left):.3f}\")\n",
    "print(f\"Right AUC: {np.mean(auc_right):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike afterhyperpolarization (AHP)\n",
    "The spike afterhyperpolarization (AHP) is the refactory period, the period where a neuron cannot fire another action potential. The AHP is defined as when the membrane voltage drops below the resting membrane potential of a neuron. However, when injecting current in slices or cell culture, you will rarely see the AHP drop below the resting membrane potential or the potential where the cell is being held instead I have seen the AHP defined as when the spike drops below the spike threshold. The are a a couple ways that you could analyze the AHP. One way is setting a cutoff after the spike for what part of the AHP you want to analyze and integrate over that period. One thing to consider with this method is that you will likely want to integrate over a percent of the AHP rather than using a strict time cutoff since the AHP will get shorter at higher spike frequencies. This is typically how people calculate the slow and fast components of the AHP. You can also find the peak or most negative component of the AHP and when it occurs. For our analysis we will analyze the voltage of the peak (most negative) AHP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring the peak AHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_ahp_peaks(voltages, peaks, pulse_end):\n",
    "    output = np.zeros(len(peaks), dtype=int)\n",
    "    for index in range(len(peaks)):\n",
    "        if index < (len(peaks) - 1):\n",
    "            t = np.argmin(voltages[peaks[index] : peaks[index + 1]]) + peaks[index]\n",
    "        else:\n",
    "            t = np.argmin(voltages[peaks[index] : pulse_end]) + peaks[index]\n",
    "        output[index] = t\n",
    "    return {\"ahp_index\": output}\n",
    "\n",
    "\n",
    "for acq in exp_dict.values():\n",
    "    voltages = acq[\"array\"]\n",
    "    peaks = acq[\"peaks\"]\n",
    "    if len(peaks) > 0:\n",
    "        output = find_all_ahp_peaks(voltages, peaks, pulse_end)\n",
    "        acq.update(output)\n",
    "    else:\n",
    "        acq[\"ahp_index\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "spike_ahp_time = []\n",
    "spike_ahp_volt = []\n",
    "for i in rheobase_acq:\n",
    "    index = exp_dict[i][\"ahp_index\"][0]\n",
    "    spike_ahp_time.append(index / 10)\n",
    "    spike_ahp_volt.append(exp_dict[i][\"array\"][index])\n",
    "print(f\"AHP time: {np.mean(spike_ahp_time):.3f} ms\")\n",
    "print(f\"AHP volt: {np.mean(spike_ahp_volt):.3f} mV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "figures = []\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, constrained_layout=True)\n",
    "ax = ax.flat\n",
    "for acq_num, a in zip(rheobase_acq, ax):\n",
    "    acq = exp_dict[acq_num]\n",
    "    sx = acq[\"ahp_index\"][0] / 10\n",
    "    sy = acq[\"array\"][acq[\"ahp_index\"][0]]\n",
    "    array = exp_dict[acq_num][\"array\"]\n",
    "    a.set_xlabel(\"Time (ms)\")\n",
    "    a.set_ylabel(\"Voltage (mV)\")\n",
    "    a.grid(which=\"both\")\n",
    "    a.spines[\"right\"].set_visible(False)\n",
    "    a.spines[\"top\"].set_visible(False)\n",
    "    a.set_xlim(sx-100, sx+200)\n",
    "    a.set_ylim(-70,45)\n",
    "    a.plot(x, array, color=\"black\")\n",
    "    a.plot(sx, sy, markersize=10, color=\"orange\", marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike derivative\n",
    "The spike derivative is useful because we can look at the currents underlying the spike itself. While we cannot see the exact Na+, K+ and Ca+ currents we can get an idea of what currents might be altered. To convert a voltage spike to current spike we must multiply the spike derivative by the capacitance of the cell since the current (I) = -C*dV/dt. The current action potential is very similar to the current action potentials that you get when you record spontaneous action potentials is cell-attached voltage-clamp mode. This equation works because a cell is a capacitor due to the lipid membrane. The first peak, or most negative peak primarily consists of Na+ currents where as the second peak likely consists of K+ and Ca+ currents [@bean_action_2007]. One interesting thing to note is the peak current in these spikes (~-2000 pA) is typically around the current you get with unclamped spikes when running a electrical/optical stimulation experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spk_velocity(dv: np.ndarray, start: int, end: int):\n",
    "    min_pos = np.argmin(dv[start:end]) + start\n",
    "    min_val = dv[min_pos]\n",
    "    max_pos = np.argmax(dv[start:end]) + start\n",
    "    max_val = dv[max_pos]\n",
    "    return min_pos, min_val, max_pos, max_val\n",
    "\n",
    "\n",
    "def find_all_spk_velocities(\n",
    "    voltages: np.ndarray,\n",
    "    spike_thresholds: np.ndarray,\n",
    "    pulse_end: int,\n",
    "    end_offset: int = 2000,\n",
    "):\n",
    "    keys = [\"min_velocity_pos\", \"min_velocity\", \"max_velocity_pos\", \"max_velocity\"]\n",
    "    velocity_measures = {key: np.zeros(spike_thresholds.size) for key in keys}\n",
    "    dv = -1 * np.gradient(voltages)\n",
    "    for index in range(spike_thresholds.size):\n",
    "        if index < (len(spike_thresholds) - 1):\n",
    "            end = spike_thresholds[index + 1]\n",
    "        else:\n",
    "            # Adding end_offset samples (or 2 ms) to the end helps with spikes that occur just before the end of the acquisition\n",
    "            if (pulse_end - spike_thresholds[index]) < end_offset:\n",
    "                end = spike_thresholds[index] + end_offset\n",
    "            else:\n",
    "                end = pulse_end\n",
    "        output = spk_velocity(dv=dv, start=spike_thresholds[index], end=end)\n",
    "        for key, value in zip(keys, output):\n",
    "            velocity_measures[key][index] = value\n",
    "    return velocity_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for acq in exp_dict.values():\n",
    "    voltages = acq[\"array\"]\n",
    "    peaks = acq[\"peaks\"]\n",
    "    if len(peaks) > 0:\n",
    "        spkt = acq[\"threshold_index\"]\n",
    "        temp = find_all_spk_velocities(voltages, spkt, pulse_end)\n",
    "        acq[\"velocity\"] = temp\n",
    "    else:\n",
    "        acq[\"velocity\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_spikes = []\n",
    "offset = int(1 * 10)\n",
    "for acq in rheobase_acq:\n",
    "    array = exp_dict[acq][\"array\"]\n",
    "    index = exp_dict[acq][\"threshold_index\"][0]\n",
    "    start = index - offset\n",
    "    if exp_dict[acq][\"threshold_index\"].shape[0] > 1:\n",
    "        end = int(exp_dict[acq][\"threshold_index\"][1])\n",
    "    else:\n",
    "        peak_x = exp_dict[acq][\"peaks\"][0]\n",
    "        thresh = exp_dict[acq][\"array\"][index]\n",
    "        ind = np.where(array[peak_x:] < thresh)[0] + peak_x\n",
    "        end = min(ind[-1], pulse_end)\n",
    "    first_spikes.append(array[start:end])\n",
    "\n",
    "min_len = min([len(i) for i in first_spikes])\n",
    "first_spikes = [i[:min_len] for i in first_spikes]\n",
    "derivative = [np.gradient(i) * -85 for i in first_spikes]\n",
    "peak_na = np.mean([min(i) for i in derivative])\n",
    "peak_k_ca = np.mean([max(i) for i in derivative])\n",
    "print(f\"Peak Na+: {peak_na} pA; Peak K+/Ca2+: {peak_k_ca} pA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, figsize=(8,3), constrained_layout=True)\n",
    "ax[0].set_ylabel(\"mV\")\n",
    "ax[1].set_ylabel(\"pA\")\n",
    "ax[1].set_xlim(0,40)\n",
    "ax[2].set_ylabel(\"pA\")\n",
    "ax[2].set_xlabel(\"mV\")\n",
    "for i in ax:\n",
    "    i.grid(which=\"both\")\n",
    "    i.spines[\"right\"].set_visible(False)\n",
    "    i.spines[\"top\"].set_visible(False)\n",
    "for i, j in zip(first_spikes, derivative):\n",
    "    x = np.arange(len(i))\n",
    "    ax[0].plot(x, i, color=\"black\", linewidth=1, alpha=0.5)\n",
    "    ax[1].plot(x, j, color=\"black\", linewidth=1, alpha=0.5)\n",
    "    ax[2].plot(i, -j, color=\"black\", linewidth=1, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membrane time constant\n",
    "The membrane time constant is the decay tau of a the exponential decay that the membrane undergoes during negative pulse injects. It gives you an idea of how membrane capacitance and resistance interact. The membrane time constant equation is: $\\tau=rc$. We have to remember that the membrane is a resistor and capacitor in parallel which means when we inject a current it will take time for the membrane to reach a steady state voltage. One factor to consider when measuring the membrane time constant is that you have to choose how to define the amplitude. Do you choose the minimum voltage which could be influenced by HCN channels causing voltage sag or do you choose the delta V that we measured earlier?  There are two way you can find the time constant. The first is you can find the time is takes for for the voltage go below 1/3 of the delta V amplitude. Or you can think if you baseline starts at some value and you end at 0, the membrane time constant is how long it takes to get to 1/3 the initial value. Alternatively you can curve fit the voltage trace to an exponential decay. We will not curve fit here because I have found it to be very tricky to curve fit, especially when you have *Ih* currents. Some neurons have voltage sag which means those neurons do not act as a pure RC circuits. Some neurons have a very square shaped voltage response (very little capacitance) which really throws off the curve fit. You can reduce the effects of HCN channels by using the negative (or positive) acquisitions that are close to 0 current injection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taus1 = []\n",
    "taus2 = []\n",
    "pulse_amps = []\n",
    "for acq in exp_dict.values():\n",
    "    acq[\"mem_tau_est1\"] = np.nan\n",
    "    acq[\"mem_tau_est2\"] = np.nan\n",
    "    if acq[\"pulse_amp\"] < 0:\n",
    "        voltages = acq[\"array\"] - acq[\"baseline_v\"]\n",
    "        threshold1 = voltages.min() * 0.63 # 1-1/np.e\n",
    "        threshold2 = acq[\"delta_v\"] * 0.63 # 1-1/np.e\n",
    "        min_val = voltages.argmin() + pulse_start\n",
    "        indices = np.where(voltages[pulse_start:min_val] < threshold1)[0][0]\n",
    "        acq[\"mem_tau_est1\"] = indices / 10\n",
    "        taus1.append(indices / 10)\n",
    "        indices = np.where(voltages[pulse_start:min_val] < threshold2)[0][0]\n",
    "        acq[\"mem_tau_est2\"] = indices / 10\n",
    "        taus2.append(indices / 10)\n",
    "print(f\"Membrane time constant (min value): {np.mean(taus1):.3f} ms\")\n",
    "print(f\"Membrane time constant (delta V): {np.mean(taus2):.3f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebound spikes\n",
    "Rebound spikes typically occur after a hyperpolarizing pulse. Dopaminergic cells typically have a rebound spike. I have not seen any analyses of the rebound spike(s), however this is feature that your cell could have and you could note the presence or number of the rebound spike(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "p = \"https://cdn.jsdelivr.net/gh/LarsHenrikNelson/PatchClampHandbook/data/rebound_spike/1.json\"\n",
    "with urllib.request.urlopen(p) as url:\n",
    "    file = json.load(url)\n",
    "array = file[\"array\"]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(array)), array, color=\"black\")\n",
    "ax.grid(which=\"both\")\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting our data\n",
    "Lastly, we will export our data to a spreadsheet. This part of the analysis is to familiarize you with the dataframe tools and methods (using Pandas), and data export (csv) in Python. I am choosing CSV export over Excel export because CSV is easier to work with downstream. This will enable you to use the notebook as a template for a semiautomated analysis if you want. Additionally the analysis we used here is part of the next section in the current clamp chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the spike parameters\n",
    "We will export the spike parameters and the general parameters separately. The spike parameters will be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = defaultdict(list)\n",
    "for key, i in exp_dict.items():\n",
    "    if i[\"voltages\"].size > 0:\n",
    "        output[\"Threshold (mV)\"].extend(i[\"array\"][i[\"threshold_index\"]])\n",
    "        output[\"Threshold (ms)\"].extend(i[\"threshold_index\"] / 10)\n",
    "        output[\"HW (ms)\"].extend((i[\"hw_right\"] - i[\"hw_left\"]) / 10)\n",
    "        output[\"HW Left (ms)\"].extend(i[\"hw_left\"] / 10)\n",
    "        output[\"HW Right (ms)\"].extend(i[\"hw_right\"] / 10)\n",
    "        output[\"HW (mV)\"].extend(i[\"hw_y\"])\n",
    "        output[\"Spike (mV)\"].extend(i[\"voltages\"])\n",
    "        output[\"Spike (ms)\"].extend(i[\"peaks\"] / 10)\n",
    "        output[\"AHP (mV)\"].extend(i[\"array\"][i[\"ahp_index\"]])\n",
    "        output[\"AHP (ms)\"].extend(i[\"ahp_index\"] / 10)\n",
    "        output[\"FW (ms)\"].extend((i[\"fw_right\"] - i[\"fw_left\"]) / 10)\n",
    "        output[\"FW Left (ms)\"].extend(i[\"fw_left\"] / 10)\n",
    "        output[\"FW Right (ms)\"].extend(i[\"fw_right\"] / 10)\n",
    "        output[\"Depol time (ms)\"].extend((i[\"peaks\"] - i[\"fw_left\"]) / 10)\n",
    "        output[\"Repol time (ms)\"].extend((i[\"fw_right\"] - i[\"peaks\"]) / 10)\n",
    "        output[\"AUC\"].extend(i[\"auc\"])\n",
    "        output[\"AUC Left\"].extend(i[\"auc_left\"])\n",
    "        output[\"AUC Right\"].extend(i[\"auc_right\"])\n",
    "        output[\"Min Velocity\"].extend(i[\"velocity\"][\"min_velocity\"])\n",
    "        output[\"Max Velocity\"].extend(i[\"velocity\"][\"max_velocity\"])\n",
    "        output[\"Min Velocity (ms)\"].extend(i[\"velocity\"][\"min_velocity_pos\"] / 10)\n",
    "        output[\"Max Velocity (ms)\"].extend(i[\"velocity\"][\"max_velocity_pos\"] / 10)\n",
    "        output[\"Spike Number\"].extend(np.arange(len(i[\"voltages\"])) + 1)\n",
    "        output[\"pulse_amp\"].extend([i[\"pulse_amp\"]] * len(i[\"voltages\"]))\n",
    "        output[\"Acq Number\"].extend([key] * len(i[\"voltages\"]))\n",
    "spike_output = pd.DataFrame(output)\n",
    "spike_output.to_csv(\"spike_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the acquisition parameters\n",
    "We will grab the acquisition parameters and we will also need to grab the first spike from each acquisition of the spike output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = defaultdict(list)\n",
    "for key, i in exp_dict.items():\n",
    "    output[\"Acq Number\"].append(key)\n",
    "    output[\"Sag (ms)\"].append(i[\"Sag (ms)\"])\n",
    "    output[\"Sag (mV)\"].append(i[\"Sag (mV)\"])\n",
    "    output[\"Delta V (mV)\"].append(i[\"delta_v\"])\n",
    "    output[\"rheobase\"].append(i[\"rheobase\"])\n",
    "    output[\"AI SFA\"].append(i[\"ai_sfa\"])\n",
    "    output[\"Local SFA\"].append(i[\"local_sfa\"])\n",
    "    output[\"rLocal SFA\"].append(i[\"rlocal_sfa\"])\n",
    "    output[\"cv\"].append(i[\"cv\"])\n",
    "    output[\"Spk Freq (Hz)\"].append(i[\"hertz\"])\n",
    "    output[\"Spk IEI (ms)\"].append(\n",
    "        np.mean(np.diff(i[\"peaks\"]) / 10) if len(i[\"peaks\"]) > 1 else np.nan\n",
    "    )\n",
    "    output[\"Mem Tau 1 (ms)\"].append(i[\"mem_tau_est1\"])\n",
    "    output[\"Mem Tau 2 (ms)\"].append(i[\"mem_tau_est2\"])\n",
    "    output[\"Baseline (mV)\"].append(i[\"baseline_v\"])\n",
    "acquisition_output = pd.DataFrame(output)\n",
    "\n",
    "first_spike_data = spike_output[spike_output[\"Spike Number\"] == 1]\n",
    "acquisition_output = pd.merge(\n",
    "    first_spike_data, acquisition_output, on=\"Acq Number\", how=\"right\"\n",
    ")\n",
    "acquisition_output.to_csv(\"acquisition_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is it for section one of current clamp analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "execution": {
   "timeout": -1
  },
  "kernelspec": {
   "display_name": "ephysbook (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
